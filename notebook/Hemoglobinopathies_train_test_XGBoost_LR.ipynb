{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TZ-PuwoyX4qQ"
   },
   "source": [
    "# Hemoglobinopathies_train_test_XGBoost_Logistic_Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZEnMK4DRNV1O"
   },
   "source": [
    "<a name='1'></a>\n",
    "# 1 - Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zrLPRsQgImel",
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "import tempfile, urllib, zipfile\n",
    "from  sklearn import experimental\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, StratifiedKFold\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    average_precision_score,\n",
    "    precision_recall_curve,\n",
    "    roc_auc_score,\n",
    "    roc_curve)\n",
    "import xgboost as xgb\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import pickle\n",
    "import pandoc\n",
    "import shap\n",
    "import util\n",
    "from scipy import stats\n",
    "\n",
    "#Suppress pandas future warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5MizoHg1DRlK"
   },
   "source": [
    "<a name='2'></a>\n",
    "# 2 - Load the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S2o2NGqIxc5e"
   },
   "source": [
    "<a name='2-1'></a>\n",
    "## 2.1 Read and Split the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YyO3RSuLF0Nf",
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# Read xlsx data into a dataframe and recognize the missing data that is encoded with '?' string as NaN\n",
    "df_affected = pd.read_excel('C:/Users/anoes/OneDrive/Documents/Aanstelling RadboudUMC/03_Thalassemie/03_Analyse/10_All_Labs/01_Data/07SEP2023_All_labs_testaffected.xlsx')\n",
    "df_gal = pd.read_excel('C:/Users/anoes/OneDrive/Documents/Aanstelling RadboudUMC/03_Thalassemie/02_Data/Galdakao/Revised/28AUG2023 - Allindices final_para_Urko - All Data.xlsx')\n",
    "df_jbz = pd.read_excel('C:/Users/anoes/OneDrive/Documents/Aanstelling RadboudUMC/03_Thalassemie/03_Analyse/10_All_Labs/01_Data/03AUG2023 Additionele interne validatie JBZ.xlsx')\n",
    "\n",
    "df_affected.drop(columns='Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gal_feat = df_gal[['Mean_Corpuscular_Volume', 'Red_Blood_Cell_Distribution_Width', 'Mean_Corpuscular_Hemoglobin',\n",
    "                      'Hemoglobin','Mean_Corpuscular_Hemoglobin_Concentration', 'Erytrocytes', 'Trombocytes', 'Diagnosis',\n",
    "                      'affected_model', 'alpha_model', 'beta_model']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='2-2'></a>\n",
    "## 2.2 Clean up data, select features, check for null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop all rows where more 5 out of 8 features is missing\n",
    "df_affected_missingness = df_affected.dropna(axis=0, how='any', thresh=5, subset=['Mean_Corpuscular_Volume', 'Red_Blood_Cell_Distribution_Width', 'Mean_Corpuscular_Hemoglobin', \n",
    "                    'Ferritin','Hemoglobin', 'Mean_Corpuscular_Hemoglobin_Concentration', 'Erytrocytes', 'Trombocytes'])\n",
    "\n",
    "#df_affected_missingness.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features of interest\n",
    "ALL_KEYS = ['Hemoglobin', 'Mean_Corpuscular_Volume', 'Mean_Corpuscular_Hemoglobin', 'Erytrocytes', 'Reticulocytes', 'Trombocytes', 'Leukocytes', 'Ferritin', 'Hemoglobin_in_Reticulocytes', 'Sex', 'GenTest']\n",
    "\n",
    "\n",
    "FEATURE_KEYS_test = ['Mean_Corpuscular_Volume', 'Red_Blood_Cell_Distribution_Width', 'Mean_Corpuscular_Hemoglobin', \n",
    "                     'Hemoglobin', 'Mean_Corpuscular_Hemoglobin_Concentration',\n",
    "                    'Erytrocytes', 'Trombocytes']\n",
    "\n",
    "FEATURE_KEYS_test_Y = ['Mean_Corpuscular_Volume', 'Red_Blood_Cell_Distribution_Width', 'Mean_Corpuscular_Hemoglobin', \n",
    "                     'Hemoglobin', 'Mean_Corpuscular_Hemoglobin_Concentration', \n",
    "                    'Erytrocytes', 'Trombocytes', 'affected_model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_missing = df_affected_missingness.groupby('Lab')[FEATURE_KEYS_test].apply(lambda x: x.notnull().sum()/len(x)*100)\n",
    "percent_missing.to_excel('C:/Users/anoes/OneDrive/Documents/Aanstelling RadboudUMC/03_Thalassemie/03_Analyse/10_All_Labs/02_Analyses/28JUN2023_Missingness_model.xlsx') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Create datasets for model assessment alpha, beta, sickle and combinations.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_alpha = df_affected_missingness[df_affected_missingness['alpha_model'].notnull()]\n",
    "df_beta = df_affected_missingness[df_affected_missingness['beta_model'].notnull()]\n",
    "df_comb = df_affected_missingness[df_affected_missingness['combinations_model'].notnull()]\n",
    "df_sikkel = df_affected_missingness[df_affected_missingness['hbs_model'] == 'Sikkelcelziekte']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_alpha_wo_med = df_alpha[df_alpha['Lab'] != 'Medlon']\n",
    "\n",
    "#df_affected_wo_med = df_affected_missingness[(df_affected_missingness['Lab'] != 'Isala') & (df_affected_missingness['Lab'] != 'Medlon')]\n",
    "\n",
    "df_alpha_med = df_alpha[df_alpha['Lab'] == 'Medlon'].sample(frac=1, random_state=38)\n",
    "df_alpha_med_mis = df_alpha_med.dropna(axis=0, how='any', thresh=7, subset=['Mean_Corpuscular_Volume', 'Red_Blood_Cell_Distribution_Width', 'Mean_Corpuscular_Hemoglobin', \n",
    "                    'Hemoglobin', 'Mean_Corpuscular_Hemoglobin_Concentration', 'Erytrocytes', 'Trombocytes'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Exclude Medlon as external validation set and collect only complete cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 Medlon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_affected_wo_med = df_affected_missingness[df_affected_missingness['Lab'] != 'Medlon'].sample(frac=1, random_state=38)\n",
    "df_affected_med = df_affected_missingness[df_affected_missingness['Lab'] == 'Medlon'].sample(frac=1, random_state=38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply one-hot encoding to sex and binary class\n",
    "compute_dummy = {'Sex': {'M': 0, \"V\": 1}, \n",
    "                'affected_model': {'Negative': 0, 'Affected': 1}\n",
    "                }       \n",
    "df_affected_med.replace(compute_dummy, inplace=True) #df_affected_med\n",
    "df_affected_med = df_affected_med[FEATURE_KEYS_test_Y].dropna() #drop all null values\n",
    "med_test = df_affected_med[FEATURE_KEYS_test]\n",
    "med_test_label = df_affected_med['affected_model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(med_test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "med_test_label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_affected_wo_med['affected_model'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 Jeroen Bosch Hospital (semi-prospective Internal Validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply one-hot encoding to sex and binary class\n",
    "compute_dummy = {'Sex': {'M': 0, \"V\": 1}, \n",
    "                'affected_model': {'Negatief': 0, 'Affected': 1}\n",
    "                }       \n",
    "df_jbz.replace(compute_dummy, inplace=True) \n",
    "\n",
    "df_jbz_2 = df_jbz[FEATURE_KEYS_test_Y].dropna()\n",
    "\n",
    "jbz_test = df_jbz_2[FEATURE_KEYS_test]\n",
    "jbz_test_label = df_jbz_2['affected_model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jbz_test_label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.3 Galdakao\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define inputs and target\n",
    "df_gal_feat_alpha = df_gal_feat[df_gal_feat['alpha_model'].notnull()]\n",
    "df_gal_feat_beta = df_gal_feat[df_gal_feat['beta_model'].notnull()]\n",
    "df_gal_feat = df_gal_feat[df_gal_feat['affected_model'].notnull()]\n",
    "\n",
    "gal_test = df_gal_feat[FEATURE_KEYS_test]\n",
    "gal_test_label = df_gal_feat['affected_model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#impute the missing platelets using iterative imputer\n",
    "imputer = IterativeImputer(max_iter=100, random_state=38)\n",
    "imputer.fit(gal_test)\n",
    "gal_test_imp = imputer.transform(gal_test)\n",
    "columns=['Mean_Corpuscular_Volume','Red_Blood_Cell_Distribution_Width','Mean_Corpuscular_Hemoglobin', 'Hemoglobin','Mean_Corpuscular_Hemoglobin_Concentration', 'Erytrocytes','Trombocytes']\n",
    "gal_test_imp = pd.DataFrame(gal_test_imp.reshape(len(gal_test_imp), -1),columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gal_test_label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gal_test.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gal_test_imp.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Create Cross Validation Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffle model development dataset (without Medlon)\n",
    "df = df_affected_wo_med.sample(frac=1, random_state=138)\n",
    "\n",
    "#Apply one-hot encoding to sex and binary class\n",
    "compute_dummy = {'Sex': {'M': 0, \"V\": 1}, \n",
    "                'affected_model': {'Negative': 0, 'Affected': 1}\n",
    "                }       \n",
    "df.replace(compute_dummy, inplace=True)\n",
    "#df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.1 IMPUTATION (optional for XGB, required for LR) & 10-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define our features and the label and split the data:\n",
    "y = df['affected_model'] #1768 (Neg=1594, Beta=247)\n",
    "X = df[FEATURE_KEYS_test]\n",
    "\n",
    "#impute the data\n",
    "imputer = IterativeImputer(max_iter=10, random_state=38)\n",
    "imputer.fit(X)\n",
    "Xtrans = imputer.transform(X)\n",
    "# the model learns that the second feature is double the first\n",
    "columns=['Mean_Corpuscular_Volume','Red_Blood_Cell_Distribution_Width','Mean_Corpuscular_Hemoglobin', 'Hemoglobin','Mean_Corpuscular_Hemoglobin_Concentration', 'Erytrocytes','Trombocytes']\n",
    "\n",
    "Xtrans = pd.DataFrame(Xtrans.reshape(len(Xtrans), -1),columns=columns)\n",
    "#convert to data format XGBoost supports for ingestion\n",
    "#data_dmatrix = xgb.DMatrix(data=Xtrans,label=y)\n",
    "\n",
    "#Stratified split of the data to preserve (potential) class imbalance:\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xtrans, y, test_size=0.2, random_state=138, stratify=y) # 70/30 train-test set\n",
    "\n",
    "#We can now get the folds using our train set. I use a repeated k-fold to get more score results :\n",
    "cv    = RepeatedStratifiedKFold(n_splits=10, n_repeats=50, random_state=138)\n",
    "folds = [(train,test) for train, test in cv.split(X_train, y_train)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrans.to_excel('C:/Users/anoes/OneDrive/Documents/Aanstelling RadboudUMC/03_Thalassemie/03_Analyse/10_All_Labs/02_Analyses/27JUL2023_Xtrans.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verify distributions with and without imputation\n",
    "Xtrans.describe().T\n",
    "X.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.1.1 Imputation split out per laboratory (internal validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab = df['Lab'].reset_index(drop=True)\n",
    "Xtrans_lab = Xtrans\n",
    "Xtrans_lab['Lab'] = lab\n",
    "Xtrans_lab['affected_model'] = df['affected_model'].reset_index(drop=True)\n",
    "Xtrans_mea = Xtrans_lab[Xtrans_lab['Lab'] == 'Meander'].sample(frac=1, random_state=38)\n",
    "Xtrans_max = Xtrans_lab[Xtrans_lab['Lab'] == 'Maxima'].sample(frac=1, random_state=38)\n",
    "Xtrans_isa = Xtrans_lab[Xtrans_lab['Lab'] == 'Isala'].sample(frac=1, random_state=38)\n",
    "Xtrans_zuy = Xtrans_lab[Xtrans_lab['Lab'] == 'Zuyderland'].sample(frac=1, random_state=38)\n",
    "Xtrans_amp = Xtrans_lab[Xtrans_lab['Lab'] == 'Amphia'].sample(frac=1, random_state=38)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.2 NO IMPUTATION (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define our features and the label and split the data:\n",
    "y = df['affected_model'] #1768 (Neg=1594, Beta=247)\n",
    "X = df[FEATURE_KEYS_test]\n",
    "\n",
    "#convert to data format XGBoost supports for ingestion\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y)\n",
    "\n",
    "#Stratified split of the data to preserve (potential) class imbalance:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4, stratify=y) # 70/30 train-test set\n",
    "\n",
    "#We can now get the folds using our train set. I use a repeated k-fold to get more score results :\n",
    "cv    = RepeatedStratifiedKFold(n_splits=10, n_repeats=50, random_state=138)\n",
    "folds = [(train,test) for train, test in cv.split(X_train, y_train)] # 70/30 train-test set per fold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.3 Internal validation: Split the test set per lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_affected_wo_med['Lab'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Isala without imputation\n",
    "df_affected_isa = df_affected_wo_med[df_affected_wo_med['Lab'] == 'Isala']\n",
    "test_set_isa = df_affected_isa.merge(X_test['Mean_Corpuscular_Volume'], left_index=True, right_index=True)\n",
    "test_set_isa.drop(columns='Mean_Corpuscular_Volume_y', inplace = True)\n",
    "test_set_isa.rename(columns={'Mean_Corpuscular_Volume_x': 'Mean_Corpuscular_Volume'}, inplace = True)\n",
    "isa_test = test_set_isa[FEATURE_KEYS_test]\n",
    "isa_test_label = test_set_isa['affected_model']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Isala with imputation\n",
    "df_affected_isa = df_affected_wo_med[df_affected_wo_med['Lab'] == 'Isala']\n",
    "test_set_isa = Xtrans_isa.merge(X_test['Mean_Corpuscular_Volume'], left_index=True, right_index=True)\n",
    "test_set_isa.drop(columns='Mean_Corpuscular_Volume_y', inplace = True)\n",
    "test_set_isa.rename(columns={'Mean_Corpuscular_Volume_x': 'Mean_Corpuscular_Volume'}, inplace = True)\n",
    "isa_test = test_set_isa[FEATURE_KEYS_test]\n",
    "isa_test_label = test_set_isa['affected_model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_isa['affected_model'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zuyderland without imputation\n",
    "df_affected_zuy = df_affected_wo_med[df_affected_wo_med['Lab'] == 'Zuyderland']\n",
    "test_set_zuy = df_affected_zuy.merge(X_test['Mean_Corpuscular_Volume'], left_index=True, right_index=True)\n",
    "test_set_zuy.drop(columns='Mean_Corpuscular_Volume_y', inplace = True)\n",
    "test_set_zuy.rename(columns={'Mean_Corpuscular_Volume_x': 'Mean_Corpuscular_Volume'}, inplace = True)\n",
    "zuy_test = test_set_zuy[FEATURE_KEYS_test]\n",
    "zuy_test_label = test_set_zuy['affected_model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zuyderland with imputation\n",
    "df_affected_zuy = df_affected_wo_med[df_affected_wo_med['Lab'] == 'Zuyderland']\n",
    "test_set_zuy = Xtrans_zuy.merge(X_test['Mean_Corpuscular_Volume'], left_index=True, right_index=True)\n",
    "test_set_zuy.drop(columns='Mean_Corpuscular_Volume_y', inplace = True)\n",
    "test_set_zuy.rename(columns={'Mean_Corpuscular_Volume_x': 'Mean_Corpuscular_Volume'}, inplace = True)\n",
    "zuy_test = test_set_zuy[FEATURE_KEYS_test]\n",
    "zuy_test_label = test_set_zuy['affected_model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_zuy['affected_model'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Amphia without imputation\n",
    "df_affected_amp = df_affected_wo_med[df_affected_wo_med['Lab'] == 'Amphia']\n",
    "test_set_amp = df_affected_amp.merge(X_test['Mean_Corpuscular_Volume'], left_index=True, right_index=True)\n",
    "test_set_amp.drop(columns='Mean_Corpuscular_Volume_y', inplace = True)\n",
    "test_set_amp.rename(columns={'Mean_Corpuscular_Volume_x': 'Mean_Corpuscular_Volume'}, inplace = True)\n",
    "amp_test = test_set_amp[FEATURE_KEYS_test]\n",
    "amp_test_label = test_set_amp['affected_model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Amphia with imputation\n",
    "df_affected_amp = df_affected_wo_med[df_affected_wo_med['Lab'] == 'Amphia']\n",
    "test_set_amp = Xtrans_amp.merge(X_test['Mean_Corpuscular_Volume'], left_index=True, right_index=True)\n",
    "test_set_amp.drop(columns='Mean_Corpuscular_Volume_y', inplace = True)\n",
    "test_set_amp.rename(columns={'Mean_Corpuscular_Volume_x': 'Mean_Corpuscular_Volume'}, inplace = True)\n",
    "amp_test = test_set_amp[FEATURE_KEYS_test]\n",
    "amp_test_label = test_set_amp['affected_model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_amp['affected_model'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Maxima without imputation\n",
    "df_affected_max = df_affected_wo_med[df_affected_wo_med['Lab'] == 'Maxima']\n",
    "test_set_max = df_affected_max.merge(X_test['Mean_Corpuscular_Volume'], left_index=True, right_index=True)\n",
    "test_set_max.drop(columns='Mean_Corpuscular_Volume_y', inplace = True)\n",
    "test_set_max.rename(columns={'Mean_Corpuscular_Volume_x': 'Mean_Corpuscular_Volume'}, inplace = True)\n",
    "max_test = test_set_max[FEATURE_KEYS_test]\n",
    "max_test_label = test_set_max['affected_model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Maxima with imputation\n",
    "df_affected_max = df_affected_wo_med[df_affected_wo_med['Lab'] == 'Maxima']\n",
    "test_set_max = Xtrans_max.merge(X_test['Mean_Corpuscular_Volume'], left_index=True, right_index=True)\n",
    "test_set_max.drop(columns='Mean_Corpuscular_Volume_y', inplace = True)\n",
    "test_set_max.rename(columns={'Mean_Corpuscular_Volume_x': 'Mean_Corpuscular_Volume'}, inplace = True)\n",
    "max_test = test_set_max[FEATURE_KEYS_test]\n",
    "max_test_label = test_set_max['affected_model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_max['affected_model'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Meander without imputation\n",
    "df_affected_mea = df_affected_wo_med[df_affected_wo_med['Lab'] == 'Meander']\n",
    "test_set_mea = df_affected_mea.merge(X_test['Mean_Corpuscular_Volume'], left_index=True, right_index=True)\n",
    "test_set_mea.drop(columns='Mean_Corpuscular_Volume_y', inplace = True)\n",
    "test_set_mea.rename(columns={'Mean_Corpuscular_Volume_x': 'Mean_Corpuscular_Volume'}, inplace = True)\n",
    "mea_test = test_set_mea[FEATURE_KEYS_test]\n",
    "mea_test_label = test_set_mea['affected_model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Meander with imputation\n",
    "df_affected_mea = df_affected_wo_med[df_affected_wo_med['Lab'] == 'Meander']\n",
    "test_set_mea = Xtrans_mea.merge(X_test['Mean_Corpuscular_Volume'], left_index=True, right_index=True)\n",
    "test_set_mea.drop(columns='Mean_Corpuscular_Volume_y', inplace = True)\n",
    "test_set_mea.rename(columns={'Mean_Corpuscular_Volume_x': 'Mean_Corpuscular_Volume'}, inplace = True)\n",
    "mea_test = test_set_mea[FEATURE_KEYS_test]\n",
    "mea_test_label = test_set_mea['affected_model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_mea['affected_model'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3'></a>\n",
    "## 3 -  Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3-1'></a>\n",
    "### 3.1 Baseline Model: XGBoost \n",
    "\n",
    "Few notes: \n",
    "- **Class Imbalance**: In the case of class imbalance (such as for specfic subclasses), is possible to scale the gradient for the loss function for the positive class differently (scale_pos_weight = total_negative_examples / total_positive_examples) this can help the model achieve better performance when making predictions on the positive class. \n",
    "- **Strong and weak features**: Based on meeting experts, I assume that some features (MCV) have strong signals and others weak. Therefore, I will set a lower learning rate and early stopping the eleviate this. Early stopping prevents overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cost-Sensitive XGBoost for class imbalance \n",
    "counter = Counter(y)\n",
    "# Estimate scale_pos_weight value, with class labels are 0 (not affected) and 1 (affected).\n",
    "#weight = counter[0] / counter[1]\n",
    "\n",
    "#Dictionary to collect results in:\n",
    "metrics = ['auc', 'fpr', 'tpr', 'avgp', 'precision', 'recall', 'thresholds']\n",
    "results = {\n",
    "    'train': {m:[] for m in metrics},\n",
    "    'val'  : {m:[] for m in metrics},\n",
    "    'test' : {m:[] for m in metrics}\n",
    "}\n",
    "\n",
    "#To initialise XGBoost we have to chose some parameters:\n",
    "params = {\n",
    "    'eta'         : '0.1', #lower learning rate\n",
    "    'objective'   : 'binary:logistic',\n",
    "    'eval_metric' : 'logloss',\n",
    "} \n",
    "\n",
    "#Run our cross validation and save all scores to our dictionary\n",
    "dtest = xgb.DMatrix(med_test, label=med_test_label)\n",
    "for train, test in tqdm(folds, total=len(folds)):\n",
    "    dtrain = xgb.DMatrix(X_train.iloc[train,:], label=y_train.iloc[train]) #enable_categorical=True\n",
    "    dval   = xgb.DMatrix(X_train.iloc[test,:], label=y_train.iloc[test]) #enable_categorical=True \n",
    "    model  = xgb.train(\n",
    "        dtrain                = dtrain,\n",
    "        params                = params, \n",
    "        evals                 = [(dtrain, 'train'), (dval, 'val')],\n",
    "        num_boost_round       = 1000, \n",
    "        verbose_eval          = False,\n",
    "        early_stopping_rounds = 20,\n",
    "    )\n",
    "    sets = [dtrain, dval, dtest]\n",
    "    for i,ds in enumerate(results.keys()):\n",
    "        y_preds              = model.predict(sets[i])\n",
    "        labels               = sets[i].get_label()\n",
    "        fpr, tpr, thresholds = roc_curve(labels, y_preds)\n",
    "        precision, recall, thresholds = precision_recall_curve(labels, y_preds)\n",
    "        results[ds]['fpr'].append(fpr)\n",
    "        results[ds]['tpr'].append(tpr)\n",
    "        results[ds]['precision'].append(precision)\n",
    "        results[ds]['recall'].append(recall)\n",
    "        results[ds]['thresholds'].append(thresholds)\n",
    "        results[ds]['auc'].append(roc_auc_score(labels, y_preds))\n",
    "        results[ds]['avgp'].append(average_precision_score(labels, y_preds))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Save XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train your XGBoost model\n",
    "# Example:\n",
    "# xgb_model = xgb.XGBClassifier()\n",
    "# xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Save the model to a file\n",
    "with open('XGB_HbP_model.pkl', 'wb') as model_file:\n",
    "    pickle.dump(model, model_file)\n",
    "\n",
    "# Load the model for predictions\n",
    "with open('XGB_HbP_model.pkl', 'rb') as model_file:\n",
    "    loaded_model = pickle.load(model_file)\n",
    "\n",
    "# convert\n",
    "dtest = xgb.DMatrix(med_test, label=med_test_label)\n",
    "    \n",
    "# Now, you can use loaded_model to make predictions\n",
    "predictions = loaded_model.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Dictionary to collect results\n",
    "metrics = ['auc', 'fpr', 'tpr', 'avgp', 'precision', 'recall', 'thresholds']\n",
    "results = {\n",
    "    'train': {m:[] for m in metrics},\n",
    "    'val'  : {m:[] for m in metrics},\n",
    "    'test' : {m:[] for m in metrics}\n",
    "}\n",
    "\n",
    "# Initialize Logistic Regression with desired parameters\n",
    "logreg_params = {\n",
    "    'penalty': 'l2',  # L2 regularization\n",
    "    'C': 1.0,  # Inverse of regularization strength\n",
    "    'solver': 'lbfgs',  # You can choose a different solver if needed\n",
    "    'max_iter': 500  #  max_iter for convergence\n",
    "}\n",
    "logreg_model = LogisticRegression(**logreg_params)\n",
    "\n",
    "# Run our cross-validation and save all scores to our dictionary\n",
    "for train, test in tqdm(folds, total=len(folds)):\n",
    "    X_train_fold, y_train_fold = X_train.iloc[train, :], y_train.iloc[train]\n",
    "    X_val_fold, y_val_fold = X_train.iloc[test, :], y_train.iloc[test]  \n",
    "\n",
    "    # Train the logistic regression model\n",
    "    logreg_model.fit(X_train_fold, y_train_fold)\n",
    "    sets = [X_train_fold, X_val_fold, med_test]\n",
    "    y_true = [y_train_fold, y_val_fold, med_test_label.astype(float)]\n",
    "    for i, ds in enumerate(results.keys()):\n",
    "        y_preds = logreg_model.predict_proba(sets[i])[:, 1]  # Predict probabilities for the positive class\n",
    "        fpr, tpr, thresholds = roc_curve(y_true[i], y_preds)\n",
    "        precision, recall, thresholds = precision_recall_curve(y_true[i], y_preds)\n",
    "        results[ds]['fpr'].append(fpr)\n",
    "        results[ds]['tpr'].append(tpr)\n",
    "        results[ds]['precision'].append(precision)\n",
    "        results[ds]['recall'].append(recall)\n",
    "        results[ds]['thresholds'].append(thresholds)\n",
    "        results[ds]['auc'].append(roc_auc_score(y_true[i], y_preds))\n",
    "        results[ds]['avgp'].append(average_precision_score(y_true[i], y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = logreg_model.coef_[0]\n",
    "tot = np.abs(coefficients)/np.abs(coefficients).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_FI = np.column_stack([FEATURE_KEYS_test, tot])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_FI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_FI_df = pd.DataFrame(LR_FI, columns=['FEATURES', 'Importance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_FI_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Save LR Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to a file\n",
    "with open('LR_HbP_model.pkl', 'wb') as model_file:\n",
    "    pickle.dump(logreg_model, model_file)\n",
    "\n",
    "# Load the model for predictions\n",
    "with open('LR_HbP_model.pkl', 'rb') as model_file:\n",
    "    loaded_model = pickle.load(model_file)\n",
    "    \n",
    "# Now, you can use loaded_model to make predictions\n",
    "predictions = loaded_model.predict_proba(med_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[:1,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='4-1'></a>\n",
    "## 4 - AUROC & AUPRC Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='4-2'></a>\n",
    "### 4.1 ROC Curve\n",
    "\n",
    "ROC Curve is useful to compare with other models trained with different data but in the same field of research. With the cross validation, the ROC is plotted with a confidence interval to show the robustness of the classifier. \n",
    "\n",
    "Sensitivity and specificity are two of the most prominent numbers that are used to measure diagnostics tests.\n",
    "- Sensitivity is the probability that our test outputs positive given that the case is actually positive.\n",
    "- Specificity is the probability that the test outputs negative given that the case is actually negative. \n",
    "\n",
    "We can phrase this easily in terms of true positives, true negatives, false positives, and false negatives: \n",
    "\n",
    "$$sensitivity = \\frac{\\text{true positives}}{\\text{true positives} + \\text{false negatives}}$$\n",
    "\n",
    "$$specificity = \\frac{\\text{true negatives}}{\\text{true negatives} + \\text{false positives}}$$\n",
    "\n",
    "- Smaller values on the x-axis of the plot indicate lower false positives and higher true negatives.\n",
    "- Larger values on the y-axis of the plot indicate higher true positives and lower false negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_FI_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#100 cross validation folds, we can plot our ROC/PRC curve:\n",
    "kind = 'test'\n",
    "c_fill      = 'rgba(45, 130, 164, 0.2)' #102, 134, 142,\n",
    "c_line      = 'rgba(45, 130, 164, 0.5)' #45, 130, 164,\n",
    "c_line_main = 'rgba(45, 130, 164, 1.0)' \n",
    "c_grid      = 'rgba(45, 130, 164, 0.5)' \n",
    "c_annot     = 'rgba(45, 130, 164, 0.5)'\n",
    "fpr_mean    = np.linspace(0, 1, 100)\n",
    "interp_tprs = []\n",
    "for i in range(100):\n",
    "    fpr           = results[kind]['fpr'][i]\n",
    "    tpr           = results[kind]['tpr'][i]\n",
    "    interp_tpr    = np.interp(fpr_mean, fpr, tpr)\n",
    "    interp_tpr[0] = 0.0\n",
    "    interp_tprs.append(interp_tpr)\n",
    "tpr_mean     = np.mean(interp_tprs, axis=0)\n",
    "tpr_mean[-1] = 1.0\n",
    "tpr_std      = 2*np.std(interp_tprs, axis=0)\n",
    "tpr_upper    = np.clip(tpr_mean+tpr_std, 0, 1)\n",
    "tpr_lower    = tpr_mean-tpr_std\n",
    "auc          = np.mean(results[kind]['auc'])\n",
    "fig = go.Figure([\n",
    "    go.Scatter(\n",
    "        x          = fpr_mean,\n",
    "        y          = tpr_upper,\n",
    "        line       = dict(color=c_line, width=1),\n",
    "        hoverinfo  = \"name+x+y\",\n",
    "        showlegend = False,\n",
    "        name       = 'upper'),\n",
    "    go.Scatter(\n",
    "       x          = fpr_mean,\n",
    "       y          = tpr_lower,\n",
    "       fill       = 'tonexty',\n",
    "       fillcolor  = c_fill,\n",
    "       line       = dict(color=c_line, width=1),\n",
    "       hoverinfo  = \"name+x+y\",\n",
    "       showlegend = False,\n",
    "       name       = 'lower'),\n",
    "    go.Scatter(\n",
    "        x          = fpr_mean,\n",
    "        y          = tpr_mean,\n",
    "        line       = dict(color=c_line_main, width=4, dash='solid'),\n",
    "        hoverinfo  = \"x+y\",\n",
    "        showlegend = True,\n",
    "        name       = f'Medlon {auc: .3f} Â±0.01' #\n",
    "    \n",
    "\n",
    "    ) \n",
    "])\n",
    "fig.add_shape(\n",
    "    type ='line', \n",
    "    line =dict(dash='dash', width=1, color='grey'),\n",
    "    x0=0, x1=1, y0=0, y1=1\n",
    ")\n",
    "fig.update_layout(\n",
    "    #template    = 'plotly_white',\n",
    "    paper_bgcolor = 'rgba(0,0,0,0)',\n",
    "    plot_bgcolor = 'rgba(0,0,0,0)',\n",
    "    title_x     = 0.5,\n",
    "    xaxis_title = \"1 - Specificity\",\n",
    "    yaxis_title = \"Sensitivity\",\n",
    "    width       = 800,\n",
    "    height      = 800,\n",
    "    legend      = dict(\n",
    "        yanchor=\"bottom\", \n",
    "        xanchor=\"right\", \n",
    "        x=1.01,\n",
    "        y=0.02,\n",
    "        font=dict(\n",
    "            size=28) \n",
    "    )\n",
    ")\n",
    "fig.update_yaxes(\n",
    "    range       = [0.0, 1.0],\n",
    "    gridcolor   = c_grid,\n",
    "    scaleanchor = \"x\", \n",
    "    scaleratio  = 1,\n",
    "    linecolor   = 'black',\n",
    "    tickfont= dict(size=32),\n",
    "    title_font=dict(size=32))  #can change the size of font here\n",
    "fig.update_xaxes(\n",
    "    range       = [0.0, 1.0],\n",
    "    gridcolor   = c_grid,\n",
    "    constrain   = 'domain',\n",
    "    linecolor   = 'black',\n",
    "    tickfont= dict(size=32),\n",
    "    title_font=dict(size=32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Calculate CI for AUCs based on CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_scores = np.array(results['test']['auc'])\n",
    "sorted_scores.sort()\n",
    "\n",
    "# Computing the lower and upper bound of the 95% confidence interval\n",
    "# You can change the bounds percentiles to 0.025 and 0.975 to get\n",
    "# a 95% confidence interval instead.\n",
    "confidence_lower = sorted_scores[int(0.025 * len(sorted_scores))]\n",
    "confidence_upper = sorted_scores[int(0.975 * len(sorted_scores))]\n",
    "print(\"Confidence interval for the score: [{:0.3f} - {:0.3}]\".format(\n",
    "    confidence_lower, confidence_upper))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_lower - confidence_upper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='4-3'></a>\n",
    "### 4.3 PRC Curve\n",
    "\n",
    "Precision-Recall is a useful measure of success of prediction when the classes are very imbalanced. \n",
    "\n",
    "In information retrieval\n",
    "- **Precision** is a measure of result relevancy and that is equivalent to\n",
    "\n",
    "$$Precision = \\frac{\\text{true positives}}{\\text{true positives} + \\text{false positives}}$$ \n",
    "\n",
    "- **Recall** is a measure of how many truly relevant results are returned and equivalent to **sensitivity**.\n",
    "\n",
    "The precision-recall curve (PRC) shows the trade-off between precision and recall for different thresholds. A high area under the curve represents both high recall and high precision, where high precision relates to a low false positive rate, and high recall relates to a low false negative rate. \n",
    "\n",
    "High scores for both show that the classifier is returning accurate results (high precision), as well as returning a majority of all positive results (high recall). Thus you know how good the routine bloods are at discriminating persons with disease from those without disease. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#100 cross validation folds, we can plot our ROC/PRC curve:\n",
    "kind = 'test'\n",
    "c_fill      = 'rgba(102, 134, 142, 0.2)'\n",
    "c_line      = 'rgba(102, 134, 142, 0.5)'\n",
    "c_line_main = 'rgba(102, 134, 142, 1.0)'\n",
    "c_grid      = 'rgba(102, 134, 142, 0.5)'\n",
    "c_annot     = 'rgba(102, 134, 142, 0.5)'\n",
    "c_highlight = 'rgba(102, 134, 142, 1.0)'\n",
    "precision_mean = np.linspace(1, 0, 100)\n",
    "interp_recalls = []\n",
    "for i in range(100):\n",
    "    precision        = results[kind]['precision'][i]\n",
    "    recall           = results[kind]['recall'][i]\n",
    "    interp_recall    = np.interp(precision_mean, precision, recall)\n",
    "    interp_recall[0] = 0.0\n",
    "    interp_recalls.append(interp_recall)\n",
    "recall_mean     = np.mean(interp_recalls, axis=0)\n",
    "recall_mean[-1] = 1.0\n",
    "recall_std      = 2*np.std(interp_recalls, axis=0)\n",
    "recall_upper    = np.clip(recall_mean+recall_std, 0, 1)\n",
    "recall_lower    = recall_mean-recall_std\n",
    "avgp            = np.mean(results[kind]['avgp'])\n",
    "fig = go.Figure([\n",
    "    go.Scatter(\n",
    "        x          = recall_upper,\n",
    "        y          = precision_mean,\n",
    "        line       = dict(color=c_line, width=1),\n",
    "        hoverinfo  = \"name+x+y\",\n",
    "        showlegend = False,\n",
    "        name       = 'upper'),\n",
    "    go.Scatter(\n",
    "        x          = recall_lower,\n",
    "        y          = precision_mean,\n",
    "        fill       = 'tonexty',\n",
    "        fillcolor  = c_fill,\n",
    "        line       = dict(color=c_line, width=1),\n",
    "        hoverinfo  = \"name+x+y\",\n",
    "        showlegend = False,\n",
    "        name       = 'lower'),\n",
    "    go.Scatter(\n",
    "        x          = recall_mean,\n",
    "        y          = precision_mean,\n",
    "        line       = dict(color=c_line_main, width=4),\n",
    "        hoverinfo  = \"x+y\",\n",
    "        showlegend = True,\n",
    "        name       = f'AUPRC: {avgp:.3f}')\n",
    "])\n",
    "\n",
    "fig.update_layout(\n",
    "    template    = 'plotly_white', \n",
    "    title_x     = 0.5,\n",
    "    xaxis_title = \"Recall\",\n",
    "    yaxis_title = \"Precision\",\n",
    "    width       = 800,\n",
    "    height      = 800,\n",
    "    legend      = dict(\n",
    "        yanchor=\"bottom\", \n",
    "        xanchor=\"right\", \n",
    "        x=0.95,\n",
    "        y=0.015,        \n",
    "        font=dict(\n",
    "            size=28)\n",
    "    )\n",
    ")\n",
    "fig.update_yaxes(\n",
    "    range       = [0.0, 1.0],\n",
    "    gridcolor   = c_grid,\n",
    "    scaleanchor = \"x\", \n",
    "    scaleratio  = 1,\n",
    "    linecolor   = 'black',\n",
    "    tickfont= dict(size=32),\n",
    "    title_font=dict(size=32))  #can change the size of font here\n",
    "fig.update_xaxes(\n",
    "    range       = [0.0, 1.0],\n",
    "    gridcolor   = c_grid,\n",
    "    constrain   = 'domain',\n",
    "    linecolor   = 'black',\n",
    "    tickfont= dict(size=32),\n",
    "    title_font=dict(size=32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_scores = np.array(results['test']['avgp'])\n",
    "sorted_scores.sort()\n",
    "\n",
    "# Computing the lower and upper bound of the 95% confidence interval\n",
    "# You can change the bounds percentiles to 0.025 and 0.975 to get\n",
    "# a 95% confidence interval instead.\n",
    "confidence_lower = sorted_scores[int(0.025 * len(sorted_scores))]\n",
    "confidence_upper = sorted_scores[int(0.975 * len(sorted_scores))]\n",
    "print(\"Confidence interval for the score: [{:0.3f} - {:0.3}]\".format(\n",
    "    confidence_lower, confidence_upper))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Individual classes - Validation\n",
    "1. Get the full validation set with the outcomes of the other models\n",
    "2. Calculate the validation sets for each class: hbs, alpha, beta, and hbc/hbe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = df_affected_med_mis.merge(med_test['Mean_Corpuscular_Volume'], left_index=True, right_index=True)\n",
    "test_set.drop(columns='Mean_Corpuscular_Volume_y', inplace = True)\n",
    "test_set.rename(columns={'Mean_Corpuscular_Volume_x': 'Mean_Corpuscular_Volume'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set['alpha_cat'].replace('alpha(+)compound heterozygoot', 'alpha(+)homo-/compound heterozygoot', inplace=True)\n",
    "test_set['alpha_cat'].replace('alpha(+)homozygoot', 'alpha(+)homo-/compound heterozygoot', inplace=True)\n",
    "test_set['beta_thal'].replace('beta-thal compound heterozygoot', 'beta-thal heterozygoot', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = test_set[test_set['hbs_model'] != 'HBS_Heterozygoot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = test_set[test_set['hbp_model'] != 'HBE']\n",
    "test_set = test_set[test_set['hbp_model'] != 'HBD']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.1 HBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hbs_sikkel_test = test_set[~test_set['hbs_model'].isnull()]\n",
    "hbs_sikkel_label = hbs_sikkel_test['hbs_model']\n",
    "hbs_sikkel_test = hbs_sikkel_test[FEATURE_KEYS_test]\n",
    "hbs_sikkel_label.value_counts()\n",
    "#hbs_sikkel_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hbs_hetero_test = test_set[~test_set['hbs_model'].isnull()]\n",
    "hbs_hetero_label = hbs_hetero_test['hbs_model']\n",
    "hbs_hetero_test = hbs_hetero_test[FEATURE_KEYS_test]\n",
    "hbs_hetero_label.value_counts()\n",
    "hbs_hetero_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.2 Alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_test = test_set[~test_set['alpha_model'].isnull()]\n",
    "alpha_test_label = alpha_test['alpha_model']\n",
    "alpha_test = alpha_test[FEATURE_KEYS_test]\n",
    "alpha_test_label.value_counts()\n",
    "#alpha_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = test_set[test_set['alpha_cat'] != 'alpha(+)heterozygoot']\n",
    "#test_set = test_set[test_set['alpha_cat'] != 'alpha(0)heterozygoot']\n",
    "test_set = test_set[test_set['alpha_cat'] != 'alpha(+)homo-/compound heterozygoot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = test_set[test_set['alpha_cat'] != 'alpha(0)heterozygoot']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.3 Beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_test = test_set[~test_set['beta_model'].isnull()]\n",
    "beta_test_label = beta_test['beta_model']\n",
    "beta_test = beta_test[FEATURE_KEYS_test]\n",
    "beta_test_label.value_counts()\n",
    "#beta_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.4 HbE/HbC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hbp_test = test_set[~test_set['hbp_model'].isnull()]\n",
    "hbp_test_label = hbp_test['hbp_model']\n",
    "hbp_test = hbp_test[FEATURE_KEYS_test]\n",
    "hbp_test_label.value_counts()\n",
    "#hbp_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.5 Combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_test = test_set[~test_set['combinations_model'].isnull()]\n",
    "comb_test_label = comb_test['combinations_model']\n",
    "comb_test = comb_test[FEATURE_KEYS_test]\n",
    "comb_test_label.value_counts()\n",
    "#hbp_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one-hot encoding\n",
    "compute_dummy = {'hbs_model': {'Negative': 0, 'Sikkelcelziekte': 1},\n",
    "                 'alpha_model': {'Negative': 0, 'Alpha': 1},\n",
    "                 'beta_model':{'Negative': 0, 'Beta': 1},\n",
    "                 'hbp_model':{'Negative': 0, 'HBC': 1, 'HBE': 1, 'HBD': 1},\n",
    "                 'combinations_model':{'Negative': 0, 'Combination': 1}\n",
    "                }       \n",
    "test_set.replace(compute_dummy, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='5'></a>\n",
    "## 5 -  Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='5'></a>\n",
    "### SHAP Values \n",
    "More info: (https://christophm.github.io/interpretable-ml-book/shapley.html)\n",
    "\n",
    "### SHAP Global Feature Importance Plot \n",
    "Global importance of each feature is taken to be the mean absolute value for that feature over all the given samples.\n",
    "\n",
    "#### Feature Redundancy\n",
    "A hierarchical clustering of the feature by training XGBoost models to predict the outcome for each pair of input features. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explain over 2000 samples in a model with over a thousand trees for XGBoost #38, 42\n",
    "explainer = shap.TreeExplainer(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.LinearExplainer(logreg_model, med_test)  #138, 138"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test set\n",
    "shap_values = explainer(med_test)\n",
    "clustering = shap.utils.hclust(med_test, med_test_label) # by default this trains (X.shape[1] choose 2) 2-feature XGBoost models\n",
    "shap.plots.bar(shap_values, clustering=clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(med_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#validation set\n",
    "#shap_values = explainer(X_test)\n",
    "#clustering = shap.utils.hclust(X_test, y_test) # by default this trains (X.shape[1] choose 2) 2-feature XGBoost models\n",
    "#shap.plots.bar(shap_values, clustering=clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance in percentages (https://github.com/slundberg/shap/issues/274)\n",
    "# Scale of the SHAP values has a linear relation (distance are equal from 2-3 and from 3-4)\n",
    "# That results in values that represent the fraction of the model output variability attributable to each feature across the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(shap_values.values).sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi_shap = abs(shap_values.values).sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi_shap = fi_shap/fi_shap.sum()\n",
    "fi_shap.sum(), fi_shap.shape, fi_shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FI = np.column_stack([FEATURE_KEYS_test, fi_shap])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FI_df = pd.DataFrame(FI, columns=['FEATURES', 'Importance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FI_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FI_df['Percentage'] = FI_df['Importance'].astype(float).apply(lambda x: 100 * x).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FI_df['Percentage']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='5-3'></a>\n",
    "### 5.3 SHAP Local Feature Importance Plot\n",
    "This plot is made of all the dots in the test data. It delivers the following information:\n",
    "\n",
    "- **Feature importance**: Variables are ranked in descending order.\n",
    "- **Impact**: The horizontal location shows whether the effect of that value is associated with a higher or lower prediction.\n",
    "- **Original value**: Color shows whether that variable is high (in red) or low (in blue) for that observation.\n",
    "- **Correlation**: A low level of âMCVâ has a high and positive impact on being affected. The âhighâ comes from the red color, and the âpositiveâ impact is shown on the X-axis.\n",
    "\n",
    "The issue with global feature importance is that prevalence is mixed with magnitude. This means that rare high magnitude effects will not appear in the feature importance plot. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shap.plots.beeswarm(shap_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.1 Interaction Plots\n",
    "Features that may interact with MCV. \n",
    "\n",
    "For Beta Thal: \n",
    "\n",
    "The amount of MCV interacts with geslacht. A lower MCV is more predictive for testing positively on Beta Thalassemia, and higher MCV for testing negative. But this relationship is stronger for men than for women. Note: this is not a causal model. \n",
    "\n",
    "HB also interacts with MCV: A higher HB combined with a lower MCV is more predictive for testing positively on Betha Thal than a lower HB. And reverse is true for testing negatively.  \n",
    "\n",
    "Ferritin: High ferritin combined with a low MCV seems to be more predictive for testing prositively on Beta Thalessemia, and high ferritin with high MCV seems to predictive for testing negatively than having a low ferritin.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds = shap.utils.potential_interactions(shap_values[:, \"Mean_Corpuscular_Volume\"], shap_values)\n",
    "\n",
    "# Plots colored by each of the top three possible interacting features\n",
    "for i in range(7):\n",
    "    shap.plots.scatter(shap_values[:,\"Mean_Corpuscular_Volume\"], color=shap_values[:,inds[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.2 Plots to explain individual predictions\n",
    "The plot below summarizes how much each feature contributes to the risk of testing positively on Alpha/Beta-Thalassemia for a particular patient. Features in red are shown to have a positive (increased) impact on the prediction, while those in blue are shown to have a negative (reduced) impact on the prediction. We can see that the amount of MCV in this case contributed to an decrease in the risk of testing positively on Beta-Thalassemia (by about 1.2).\n",
    "\n",
    "Note: These relationships are not necessarily causal. Feature impact can be due to correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_names = ['MCV', 'RDWCV', 'MCH', 'Hb', 'MCHC', 'RBC',  'Plt']\n",
    "\n",
    "# Individualized Explanations for each Patient\n",
    "shap.initjs()\n",
    "shap_values = explainer.shap_values(med_test)\n",
    "shap.force_plot(explainer.expected_value, shap_values[436,:], med_test.iloc[436,:], feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "med_test[436:437]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "med_test_label[436:437]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do the same for all patients in the test set (and cluster them)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 - Get Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_ML = model.predict(xgb.DMatrix(med_test))\n",
    "predictions_ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_LR = logreg_model.predict_proba(med_test)[:, 1] \n",
    "len(predictions_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "med_test['LR_preds'] = predictions_LR\n",
    "med_test['ML_preds'] = predictions_ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Medlon_test_set = pd.concat([med_test, med_test_label], axis=1)\n",
    "Medlon_test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"./Validation_data.xlsx\"\n",
    "\n",
    "with pd.ExcelWriter(file_path) as writer:  \n",
    "    Medlon_test_set.to_excel(writer, sheet_name='Validation_data', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
